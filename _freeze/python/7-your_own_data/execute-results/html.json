{
  "hash": "bd26c6be65fb4496a310b52c4609c128",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Analysing your own data\n--- \n\nIn this final session, we look at taking the skills we've developed during the intensive and applying it to your own data. We'll also discuss a few common pitfalls and where to get help in the wild.\n\n* Accessing your data\n* Importing your data\n* Cleaning your data\n* How to get help\n* Now go!\n\n## Environments and importing data\n\nPerhaps the most frustrating issues are those which prevent you from importing the data at all!\n\n### Getting your setup right\nNobody likes to encounter this:\n\n::: {#9fee0e25 .cell execution_count=1}\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">FileNotFoundError</span>                         Traceback (most recent call last)\nCell <span class=\"ansi-green-fg\">In[1], line 1</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">raise</span> <span style=\"font-weight:bold;color:rgb(215,95,95)\">FileNotFoundError</span>(<span style=\"color:rgb(175,0,0)\">\"</span><span style=\"color:rgb(175,0,0)\">PANIC!</span><span style=\"color:rgb(175,0,0)\">\"</span>)\n\n<span class=\"ansi-red-fg\">FileNotFoundError</span>: PANIC!</pre>\n```\n:::\n\n:::\n:::\n\n\nTo solve it, we need to talk about filesystems.\n\nWhen running a Python script, there are always three relevant locations:\n\n* Your Python executable\n* Your script\n* Your working directory\n\nThe Python executable runs your script **from the working directory**\n\nWhy does this matter? Because when you import data, Python uses your **working directory** as the reference, not the others. This means that there are important questions you need to ask:\n\n1. Where is your working directory?\n2. Where is your data?\n\nAnswering the first question is easy: simply run\n\n::: {#2642140b .cell execution_count=2}\n``` {.python .cell-code}\nimport os\nos.getcwd()\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\n'/home/uqcwest5/tech_training/training-intensives/python'\n```\n:::\n:::\n\n\n:::{.callout-note}\n## Alternatively\n\n* When you run Python from the command line, it's the current location as specified in the terminal\n* When you run Python in Spyder, it's the folder displayed in \"Files\" and given by the address in the **top right**.  \n:::\n\nThis address is your working directory. All paths in your scripts are evaluated relative to this location. This includes your data.\n\nThe data path can be absolute or relative, and it can be online.\n\nAbsolute paths begin with a root prefix and have folders separated with slashes. They contain **all** the folders from the root of the filesystem down to the object of interest.\n\n:::{.panel-tabset group=\"os\"}\n\n## Windows\n\nOn Windows, absolute paths are prefixed with the drive, e.g. `C:\\`: and folders separated with backslashes `\\`\n\n```\nC:\\Users\\...\\...\\data\\example.csv\n```\n\n## Unix-like (e.g. macOS, Ubuntu)\n\nOn unix-like systems, absolute paths are prefixed with a forwardslash `/`, which also separate folders.\n\n```\n/home/user/.../.../data/example.csv\n```\n\nAlternatively, you also have the option to start from your 'user' directory by prefixing with a tilde `~`:\n\n```\n~/.../.../data/example.csv\n```\n\n## URL\n\nWebsite and web-hosted files can typically be accessed with URLs. Full or 'absolute' URLs are prefixed with a protocol (e.g. `https://`) and a hostname (e.g. `www.website.com`), with folders then separated by forwardslashes\n\n```\nhttps://www.website.com/.../.../.../data/example.csv\n```\n\n:::\n\nRelative filepaths have no prefix. \n\n:::{.panel-tabset group=\"os\"}\n\n## Windows\n\nOn Windows, relative paths are still separated with backslashes\n\n```\ndata\\example.csv\n```\n\n## Unix-like (e.g. macOS, Ubuntu)\n\nOn unix-like systems, relative paths are still separated with forwardslashes\n\n```\ndata/example.csv\n```\n\n## URL\n\nIt's possible to have a relative path to a web file, however, as a relative filepath, you **must be running Python from the server.**\n\nThe syntax is the same as unix-like systems, i.e., folders separated with forwardslashes\n\n```\ndata/example.csv\n```\n\n:::\n\n:::{.callout-note}\n# Should I use absolute or relative paths?\n\n+----------+---------------------------------------------------------+--------------------------------------------------------------------+\n|          | Pros                                                    | Cons                                                               |\n+----------+---------------------------------------------------------+--------------------------------------------------------------------+\n| Absolute | * Works for any working directory (on same device)      | * Only valid on one device                                         |\n|          |                                                         | * Can get long                                                     |\n|          |                                                         | * Can contain irrelevant information                               |\n+----------+---------------------------------------------------------+--------------------------------------------------------------------+\n| Relative | * Works on any device with the same *project* structure | * Working directory must be set up correctly                       |\n|          | * Only contains project-specific information            | * Can become confusing with many parent folders (e.g. `../../../`) |\n|          | * Can be shorter                                        |                                                                    |\n+----------+---------------------------------------------------------+--------------------------------------------------------------------+\n:::\n\nOnce you have your working directory and your filepath, you check the location has been specified correctly.\n\n**If the path is absolute**\n\nYou just need to ensure that your working directory is on the same device as the file. \n\n**If the path is relative**\n\nGo to the working directory and trace the path to ensure it's correct. The path begins *inside* the working directory. A few oddities:\n\n* `..` indicates go *up* a folder\n* `.` indicates the current folder\n\n:::{.callout-note}\n# Changing the working directory\n\nIf you need to change working directories, you can do this with Python code,\n\n```python\nos.chdir(\"path/to/new/dir\")\n```\n\nOr in Spyder by changing the address in the top-right.\n:::\n\nYou could also run into issues if there's something wrong with the filepath *syntax*. In Python, we use the `pd.read_csv` function:\n\n```python\nimport pandas as pd\npd.read_csv(\"path/to/data.csv\")\n```\n\n:::{.callout-warning}\n# Watch out Windows users\n\nThe backslashes in Windows paths conflict with Python's escape character in strings (also a backslash). To fix this, you can\n\n* Replace backslashes with forwardslashes **in Python**\n* Prefix the string with `R` to ignore the backslashes\n* Escape the backslashes with an *extra* backslash\n\nFor example, the following Windows path\n\n<i>\n```{bash filename=\"Windows path\"}\nC:\\Users\\me\\data\\secrets.csv\n```\n</i>\n\ncould be imported as any of the following\n\n```python\n# Prefix with R\"...\npd.read_csv(R\"C:\\Users\\me\\data\\secrets.csv\")\n\n# Replace with forwardslashes\npd.read_csv(\"C:/Users/me/data/secrets.csv\")\n\n# Escape the backslashes\npd.read_csv(\"C:\\\\Users\\\\me\\\\data\\\\secrets.csv\")\n```\n\nWe recommend using the `R\"...\"` option where possible, as it's the least work.\n:::\n\nIf you've fixed the filepath and you're on top of the Windows peculiarities, then check the following errors for more troubleshooting.\n\n:::{.callout-warning collapse=\"true\"}\n# `SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes ...`\n\nYou've probably used a path with backslashes and not adjusted it for Python. See \"Watch out Windows users\" above.\n\nPython throws this error when it runs `\"\\u...\"` or `\"\\U...\"` (unless `\"...\"` is a valid unicode code; `\\Users` is not).\n\n:::\n\n:::{.callout-warning collapse=\"true\"}\n# `FileNotFoundError: [Errno 2] No such file or directory ...` but everything is correct???\n\nHave you used a path with backslashes on a non-Windows machine? If you have, replace them with forwardslashes.\n:::\n\nFinal thoughts\n\n* Avoid spaces\n* Use relative filepaths where possible\n* Get familiar with your working directory\n* Use forward slashes in filepaths in Python\n\n### Importing your data correctly\n\nOnce you've got the path working, the next challenge will be importing the data correctly. Unlike our data, yours might have multiple header rows, missing data, simply be organised differently or even be a different file type.\n\nWe'll look at importing .csv files here, but the same applies to other file types.\n\nThe documentation for [`pd.read_csv`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) explains (as of v2.3) 49 different parameters that the functions supports. These include\n\n| Parameter | Description | \n| --- | --- |\n| `filepath_or_buffer` | The path (**doesn't have to actually be `.csv`!**) | \n| `sep` | The separator (use `\"\\t\"` for tab separated values) |\n| `header` | The row number(s) containing headers (pass `header=None` for no header) | \n| `skiprows` | Skip certain rows (by number **from 0**) | \n| `na_values` | A list of values to interpret as empty cells | \n| `parse_dates` | A list of column names to interpret as datetimes (other options as well, see docs) | \n\nThere are plenty more! Check these out if your data isn't importing correctly.\n\nAdditionally, you can import other types of files. See the [IO tools](https://pandas.pydata.org/docs/user_guide/io.html) user guide for using file types, like .xlsx (Excel workbooks), JSON, etc.\n\n:::{.callout-tip}\n# MS Excel files (`.xlsx`)\n\nReading `.xlsx` files can be complicated, but for simple reading, just use\n\n```python\npd.read_excel(...)\n```\n\nwith `sheet_name=\"...\"` if you'd like to specify the sheet.\n:::\n\n\n## Dealing with different and dodgy data\n\nOur data has been set up to be a bit of a challenge, and a bit of a help. Your data might be organised differently, and might need more work! You might also need to perform different tasks.\n\nWe'll look at a few common tips to get you going, but before you start, the best advice is to get out a pencil and paper and draw. Mock up your data, figure out what you want and write down the steps that you would have to do *by hand*. Then you'll have a good grasp of what you want, and whether the code is working.\n\nA few resources that you should consult:\n\n* [The official pandas User Guide](https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html) is comprehensive and will likely provide tutorial support for your use cases. **Start here**.\n* [The pandas cheatsheet](https://github.com/pandas-dev/pandas/blob/main/doc/cheatsheet/Pandas_Cheat_Sheet.pdf) is a fantastic resource which outlines the common pandas tasks along with diagrams of the tabular operations. **Consult this often!**\n* [The pandas API reference](https://pandas.pydata.org/pandas-docs/stable/reference/index.html) is a succinct reference of each pandas function. Scroll through the `Series` options for column-based functions to see if any sound appropriate, or learn how to use one you've discovered.\n\nSee below for a summary of data cleaning tips you might need to apply to your data, assuming your data is stored in `df` and `\"col_name\"` is a column name\n\n### Reshaping your data\n\nFor simple (or complex) reshaping tasks, like filtering, subsetting and adding new columns, refresh yourself with our second session of this intensive: [2 - Data Processing](./Essentials/2-Data_processing.qmd). Alternatively, the read one of the following user guide articles\n\n* [10 minutes to pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html)\n* [Indexing and selecting data](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html)\n* [Merge, join, concatenate and compare](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html)\n* [Reshaping and pivot tables](https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html)\n\n\n### Cleaning up inconsistencies\n\n| Function | Description |\n| --- | --- | \n| `df.replace(\"old\",\"new\")` | Replace all values `\"old\"` in a **dataframe**  with `\"new\"` |\n| `df[\"col_name\"].replace(\"old\",\"new\")` | Replace all values `\"old\"` in a **column**  with `\"new\"` | \n| `df.rename(columns = {\"old_col\": \"new_col\"})`| Replace column name `\"old_col\"` with `\"new_col\"` | \n| `df.fillna(\"new_na\")` | Replace all NA/empty in a **dataframe** values with `\"new_na\"` | \n| `df[\"col_name\"].fillna(\"new_na\")` | Replace all NA/empty values in a **column** with `\"new_na\"` | \n\n### Dealing with different types of data\n\nEach series (column) in pandas is stored as a particular dtype (data type). Common types include\n\n* `object` for generic non-numeric data. Each cell can contain any Python object, almost always strings but occasionally lists. Mixed types will default to `object`.\n* `int64` for integers.\n* `float64` for decimals (including scientific notation).\n* `bool` for booleans (`True` or `False`)\n* `datetime64[ns]` for timestamps\n* `category` for categorical data\n\nFor applying methods specific to **textual**, **temporal** or **cateogrical** data, you must first ensure the columns match the dtype you expect. Common mishaps include\n\n* Timestamps or categorical stored as `object` dtypes\n* Numeric categorical data stored as `int64` or `float64` dtypes\n\nBy default all timestamps and categorical data are read in as `object`s. You can modify `pd.read_csv()` at the import stage, otherwise use `.astype()` to change a column's type (or `pd.to_datetime` in the case of timestamps):\n\n```python\ndf[\"A\"] = pd.to_datetime(df[\"A\"])       # <-- Time series\ndf[\"A\"] = df[\"A\"].astype(\"category\")    # <-- Categorical\ndf[\"A\"] = df[\"A\"].astype(\"object\")      # <-- Object (e.g. string data)\n```\n\nWe'll look at these more in the respective sections below.\n\n:::{.callout-note}\n# String changes in pandas v3.0\n\nPandas v3.0 changes the (default) behaviour for string columns. They are longer be `object` dtypes, but `str` dtypes (by default). Most features will work the same, but it may cause some breaking changes: see the [migration user guide](https://pandas.pydata.org/pandas-docs/stable/user_guide/migration-3-strings.html) for details.\n\nAs of December 2025, pandas 3.0 is still in the final stages of development.\n:::\n\n\nIn general, pandas allows you to apply type-specific methods with specific accessors:\n\n* `df[\"col_name\"].str` contains *string* methods\n* `df[\"col_name\"].dt` contains *datetime* methods \n* `df[\"col_name\"].cat` contains *categorical* methods\n\nWe'll go through a few useful ones here. Note that \n\n* `.str` methods only work on `object` dtypes\n* `.dt` methods only work on `datetime64[ns]` dtypes\n* `.cat` methods only work on on `category` types.\n\n#### Textual (`.str` methods)\n\nWhen performing text analysis, or for simple string methods, use the methods in `df[\"col_name\"].str`. \n\n:::{.callout-tip}\n# Consult the [user guide](https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html)\n\nYou should consult the official *[Working with text data](https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html)* user guide for details about string operations. We've included a brief summary of some useful functions here.\n:::\n\nFor each example below, append `.method` to `df[\"col_name\"]`. For example, the method `.str.replace` should be used as `df[\"col_name\"].str.replace()`. Each function is applied to **every row in \"col_name\"**\n\n| Method | Description |\n| --- | --- |\n| `.str.cat(...)` | Concatenate one or more strings to the end | \n| `.str.split(...)` | Split the string into a list of strings based on a common delimiter. Inverse of `.join()` | \n| `.str.join(...)` | Join a list of strings into a single string based on a delimiter. Inverse of `.split()` | \n| `.str.contains(...)` | Return `True`/`False` if the string contains `...`. Useful for filtering: `df[df[\"col_name\"].str.contains(...)]` will subset for those rows in \"col_name\" which contain \"...\". | \n| `.str.slice(...)` | Return a slice of the strings | \n\n#### Time series (`.dt` methods)\n\nWhen performing time series analysis, or for simple temporal methods, use the methods in `df[\"col_name\"].dt`.\n\nNote that the column **must be a `datetime64[ns]` dtype** (you could change the `[ns]` to a different precision if you'd prefer, like millisecond `[ms]` or second `[s]`). To set column `df[\"col_name\"]`, use [pd.to_datetime](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html)\n\n```python\ndf[\"col_name\"] = pd.to_datetime(df[\"col_name\"])`\n```\n\nInclude `format=\"...\"` to specify the format of your timestamps, according to the [standard Python datetime syntax](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior). For example, `format=\"%d/%m/%y\"` matches two-digit DD/MM/YY, e.g. 03/02/26.\n\nIf the timestamp is spread across multiple columns, e.g.\n\n::: {#22747683 .cell execution_count=3}\n\n::: {.cell-output .cell-output-stdout}\n```\n   day  month  year\n0   21      3  1987\n1    7      8  2000\n2   15     12  2026\n```\n:::\n:::\n\n\nyou can use `pd.to_datetime` on those columns (or the whole dataframe if there's nothing else) to convert them into a single time series\n\n::: {#e88946ad .cell execution_count=4}\n``` {.python .cell-code}\npd.to_datetime(temporal[[\"day\", \"month\", \"year\"]])\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n0   1987-03-21\n1   2000-08-07\n2   2026-12-15\ndtype: datetime64[ns]\n```\n:::\n:::\n\n\n:::{.callout-tip}\n# Consult the [user guide](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html)\n\nYou should consult the official *[Time series / date functionality](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html)* user guide for details about temporal operations. We've included a brief summary of some useful functions here.\n:::\n\nFor each example below, append `.method` to `df[\"col_name\"]`. For example, the method `.dt.date` should be used as `df[\"col_name\"].dt.date`. Each function is applied to **every row in \"col_name\"**\n\n| Method | Description |\n| --- | --- |\n| `.dt.date` | Return the date part of the timestamp (this is technically an *attribute*, meaning it's not a function and should not have brackets `()`) | \n| `.dt.weekday()` | Return the day of the week corresponding to the date | \n| `dt.normalize()` | Convert all times to midnight | \n| `.dt.strftime(...)` | Convert a timestamp to a string. Send the format into `...` according to the [standard Python datetime syntax](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior) | \n| `.resample(...)` | For time-based grouping, e.g. average/max/median $x$ per day/hour/minute. Note that this is ***not*** a `.dt` method - it applies directly to the column: `df[\"col_name\"].resample(...)` |\n\n##### Filtering\n\nYou can filter particular parts of the timestamp as normal, because they're just numbers:\n\n```python\ndf[df[\"col_name\"].year == 2026]\n```\n\nHowever, you might want to filter from or before a particular *timestamp*. To do this, use a `pd.Timestamp` in the condition, e.g. for timestamps after 3rd Feb 2026,\n\n```python\ndf[df[\"col_name\"] > pd.Timestamp(2026, 2, 3)]\n```\n\n#### Categorical (`.cat` methods)\n\nWhen analysing categorical data, you can use the methods in `df[\"col_name\"].cat`. These are particularly useful for data with ordered levels.\n\nTo make a column the `\"category\"` type, use `.astype(\"category\")`:\n\n```python\ndf[\"col_name\"] = df[\"col_name\"].astype(\"category\")\n```\n\n:::{.callout-tip}\n# Consult the [user guide](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html)\n\nYou should consult the official *[Categorical data](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html)* user guide for details about categorical operations. We've included a brief summary of some useful functions here.\n:::\n\nFor each example below, append `.method` to `df[\"col_name\"]`. For example, the method `.cat.categories` should be used as `df[\"col_name\"].cat.categories`. Each function is applied to **every row in \"col_name\"**.\n\n| Method | Description |\n| --- | --- |\n| `.cut(...)` | Group a numeric data into discrete bins. **Apply to numeric columns**, returns a category column. | \n| `.cat.categories` | Return the categories in the column. | \n| `.cat.reorder_categories(..., ordered=True)` | Change the category order. Exclude `ordered=True` if the data is not ordered. | \n| `.sort_values(...)` | Sort the column based on the category order. Will fail if `.cat.ordered == False`, and will work for non-category columns (sorting alphabetically for strings and numerically for numbers). |\n\n#### Geospatial\n\nTo manage geospatial data, you should use the [`geopandas`](https://geopandas.org/en/stable/index.html) package. With geopandas, you create GeoDataFrames, which behave like pandas DataFrames with additional behaviour for geospatial columns. Let us know if you'd like help with this!\n\n## What to do when you don't know what to do\n\n1. **Consult the documentation**. If your function isn't behaving, go to the specific page for that function. Otherwise, consult a relevant [user guide](https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html).\n2. **Search the web for your issue** to find practical and canonical approaches to typical data cleaning tasks. [Stackoverflow is your friend](https://stackoverflow.com/questions/tagged/pandas).\n3. **Ask us while we're here!** And once we're gone, shoot us an email at [training@library.uq.edu.au](mailto:training@library.uq.edu.au)\n4. Lots of people also ask AI. There are pros and cons, but beware: you'll get a solution that *probably* works, but if you don't know why, **you should double check the data matches what you want** (and try learn what it's done!).\n\n## Common errors\n\n\n\n## Now give it a go!\n\nFor the rest of this session, we'd love to help you get your data set up and working on your end. For that reason, we've dedicated this time to troubleshooting any issues that arise together. Good luck!\n\n",
    "supporting": [
      "7-your_own_data_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}